{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Capstone Project: Predict severity of an accident__\n",
    "### Applied Data Science Capstone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "* [Introduction: Business Problem](#introduction)\n",
    "* [Data](#data)\n",
    "* [Methodology](#methodology)\n",
    "* [Results and Discussion](#results)\n",
    "* [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Introduction: Business Problem__ <a name=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traffic accidents are a recurring problem in every corner of the world, perhaps the biggest problem are the injuried people. The first problem is the fatality of the injured, the second problem is the possibility of being seriously injured. Another problem no less important are the costs in repairing damages, costs that insurers assume, costs that governments assume and a long list of affected.\n",
    "\n",
    "Governments in each country should analyze these types of studies to issue laws that try to reduce the risk of traffic accidents, the frequent driver who goes to their work every day should know the prevention recommendations that come from these reports because they aim to take care of their lives and the lives of their families."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Data__ <a name=\"data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has 37 features but we only use the next list: 'INATTENTIONIND', 'UNDERINFL', 'SPEEDING', 'LIGHTCOND', 'ROADCOND', 'WEATHER', 'SEVERITYCODE'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "collisions_base = pd.read_csv('Data-Collisions.csv',low_memory=False)\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 194673 entries, 0 to 194672\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   INATTENTIONIND  29805 non-null   object\n",
      " 1   UNDERINFL       189789 non-null  object\n",
      " 2   SPEEDING        9333 non-null    object\n",
      " 3   LIGHTCOND       189503 non-null  object\n",
      " 4   ROADCOND        189661 non-null  object\n",
      " 5   WEATHER         189592 non-null  object\n",
      " 6   SEVERITYCODE    194673 non-null  int64 \n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 10.4+ MB\n"
     ]
    }
   ],
   "source": [
    "collisions = collisions_base[['INATTENTIONIND', 'UNDERINFL', 'SPEEDING', 'LIGHTCOND', 'ROADCOND', 'WEATHER', 'SEVERITYCODE']].copy()\n",
    "collisions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data receive binary processing where the value one (1) represents whether the feature influences the severity of the accident and the other way around (does not influence severity) is given by the value zero (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 194673 entries, 0 to 194672\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count   Dtype\n",
      "---  ------          --------------   -----\n",
      " 0   INATTENTIONIND  194673 non-null  int32\n",
      " 1   UNDERINFL       194673 non-null  int32\n",
      " 2   SPEEDING        194673 non-null  int32\n",
      " 3   LIGHTCOND       194673 non-null  int32\n",
      " 4   ROADCOND        194673 non-null  int32\n",
      " 5   WEATHER         194673 non-null  int32\n",
      " 6   SEVERITYCODE    194673 non-null  int32\n",
      "dtypes: int32(7)\n",
      "memory usage: 5.2 MB\n"
     ]
    }
   ],
   "source": [
    "new_values = {'INATTENTIONIND': {'N':'0', 'Y':'1',np.nan:'0'},\n",
    "              'UNDERINFL': {'N':'0', 'Y':'1',np.nan:'0'},\n",
    "              'SPEEDING':  {'N':'0', 'Y':'1',np.nan:'0'}}\n",
    "collisions.replace(new_values,inplace=True)\n",
    "\n",
    "new_values = {'LIGHTCOND':{'Daylight':'0','Dark - Street Lights On': '1', 'Unknown': '1', 'Dusk': '1', \n",
    "                            'Dawn': '1', 'Dark - No Street Lights': '1', 'Dark - Street Lights Off': '1',\n",
    "                            'Other': '1', 'Dark - Unknown Lighting':'1',np.nan:'1'},\n",
    "              'ROADCOND':{'Dry':'0', 'Wet': '1', 'Unknown':'1', 'Ice':'1',\n",
    "                              \"Snow/Slush\":'1', \"Other\":'1', \"Standing Water\":'1',\n",
    "                              'Sand/Mud/Dirt':'1', 'Oil':'1',np.nan:'1'},\n",
    "              'WEATHER':{'Clear':'0', 'Raining':'1', 'Overcast':'1', 'Unknown':'1',\n",
    "                              'Snowing':'1', 'Other':'1', 'Fog/Smog/Smoke':'1', 'Sleet/Hail/Freezing Rain':'1',\n",
    "                              'Blowing Sand/Dirt':'1', 'Severe Crosswind':'1', 'Partly Cloudy':'1',np.nan:'1'}}\n",
    "collisions.replace(new_values, inplace=True)\n",
    "# use 'int' type date for future treatment \n",
    "collisions = collisions.astype(int)\n",
    "\n",
    "collisions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbalanced data is a feature of such datasets to address such problems, data subsampling is used to balance the two current data classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "The actual unbalanced data for SEVERITYCODE is:\n",
      "---------------------------------------\n",
      "1    136485\n",
      "2     58188\n",
      "Name: SEVERITYCODE, dtype: int64\n",
      "---------------------------------------\n",
      "The subsample data now is:\n",
      "---------------------------------------\n",
      "2    58188\n",
      "1    58188\n",
      "Name: SEVERITYCODE, dtype: int64\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('---------------------------------------')\n",
    "print('The actual unbalanced data for SEVERITYCODE is:')\n",
    "print('---------------------------------------')\n",
    "print(collisions.SEVERITYCODE.value_counts())\n",
    "print('---------------------------------------')\n",
    "df_majority = collisions[collisions.SEVERITYCODE == 1]\n",
    "df_minority = collisions[collisions.SEVERITYCODE == 2]\n",
    "df_majority_downsampled = resample(df_majority,replace=False,n_samples=58188,random_state=1)\n",
    "df_downsampled = pd.concat([df_majority_downsampled,df_minority])\n",
    "print('The subsample data now is:')\n",
    "print('---------------------------------------')\n",
    "print(df_downsampled.SEVERITYCODE.value_counts())\n",
    "print('---------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Methodology__ <a name=\"methodology\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the features in two data sets: internal causes (for those driver's responsability) and external causes (for those related to road, weather conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions_internal = df_downsampled[['INATTENTIONIND', 'UNDERINFL', 'SPEEDING','SEVERITYCODE']].copy()\n",
    "collisions_external = df_downsampled[['LIGHTCOND', 'ROADCOND', 'WEATHER', 'SEVERITYCODE']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Modeling__\n",
    "\n",
    "Let's work with internal causes first applyng Logistic Regression (LR) and Random Forest Classifier (RFC).\n",
    "\n",
    "For LR we use two options for class_weight: default (with balanced data) and balanced (with inbalanced data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation: 0.5349\n",
      "Probabilistic Evaluation: 0.6901\n"
     ]
    }
   ],
   "source": [
    "x = collisions_internal.drop('SEVERITYCODE',axis=1)\n",
    "y = collisions_internal.SEVERITYCODE\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# modeling\n",
    "LR = LogisticRegression(solver='lbfgs')\n",
    "LR.fit(x_train, y_train)\n",
    "y_hat = LR.predict(x_test)\n",
    "\n",
    "# evaluating\n",
    "print('Model Evaluation:',jaccard_similarity_score(y_test, y_hat).round(4))\n",
    "y_prob = LR.predict_proba(x_test)\n",
    "print('Probabilistic Evaluation:', log_loss(y_test, y_prob).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2]), array([17630,  5646], dtype=int64))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_hat,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation: 0.6343\n",
      "Probabilistic Evaluation: 0.69\n"
     ]
    }
   ],
   "source": [
    "x1 = collisions[['INATTENTIONIND', 'UNDERINFL', 'SPEEDING']]\n",
    "y1 = collisions.SEVERITYCODE\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(x1, y1, test_size=0.2, random_state=1)\n",
    "\n",
    "#m modeling\n",
    "LR1 = LogisticRegression(solver='lbfgs', class_weight='balanced')\n",
    "LR1.fit(x_train1, y_train1)\n",
    "y_hat1 = LR1.predict(x_test1)\n",
    "\n",
    "# evaluating\n",
    "print('Model Evaluation:',jaccard_similarity_score(y_test1, y_hat1).round(4))\n",
    "y_prob1 = LR1.predict_proba(x_test1)\n",
    "print('Probabilistic Evaluation:',log_loss(y_test1, y_prob1).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2]), array([29849,  9086], dtype=int64))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_hat1,return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the case of RFC we use three options for class_weight: default (with balanced data), balanced (with inbalanced data), and subsample (with inbalanced data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation: 0.5349\n",
      "Probabilistic Evaluation: 0.69\n"
     ]
    }
   ],
   "source": [
    "# class_weight = 'none'\n",
    "x2 = collisions_internal.drop('SEVERITYCODE',axis=1)\n",
    "y2 = collisions_internal.SEVERITYCODE\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x2, y2, test_size=0.2, random_state=1)\n",
    "\n",
    "# modeling\n",
    "RFC2 = RandomForestClassifier(n_estimators=10)\n",
    "RFC2.fit(x_train2,y_train2)\n",
    "y_hat2 = RFC2.predict(x_test2)\n",
    "\n",
    "# evaluating\n",
    "print('Model Evaluation:',jaccard_similarity_score(y_test2, y_hat2).round(4))\n",
    "y_prob2 = RFC2.predict_proba(x_test2)\n",
    "print('Probabilistic Evaluation:',log_loss(y_test2, y_prob2).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2]), array([17630,  5646], dtype=int64))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_hat2,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation: 0.6343\n",
      "Probabilistic Evaluation: 0.6899\n"
     ]
    }
   ],
   "source": [
    "# class_weight = 'balanced'\n",
    "x3 = collisions[['INATTENTIONIND', 'UNDERINFL', 'SPEEDING']]\n",
    "y3 = collisions.SEVERITYCODE\n",
    "x_train3, x_test3, y_train3, y_test3 = train_test_split(x3, y3, test_size=0.2, random_state=1)\n",
    "\n",
    "# modeling\n",
    "RFC3 = RandomForestClassifier(n_estimators=10, class_weight ='balanced')\n",
    "RFC3.fit(x_train3,y_train3)\n",
    "y_hat3 = RFC3.predict(x_test3)\n",
    "\n",
    "# evaluating\n",
    "print('Model Evaluation:',jaccard_similarity_score(y_test3, y_hat3).round(4))\n",
    "y_prob3 = RFC3.predict_proba(x_test3)\n",
    "print('Probabilistic Evaluation:',log_loss(y_test3, y_prob3).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2]), array([29849,  9086], dtype=int64))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_hat3,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation: 0.6343\n",
      "Probabilistic Evaluation: 0.69\n"
     ]
    }
   ],
   "source": [
    "# class_weight = 'balanced_subsample'\n",
    "x4 = collisions[['INATTENTIONIND', 'UNDERINFL', 'SPEEDING']]\n",
    "y4 = collisions.SEVERITYCODE\n",
    "x_train4, x_test4, y_train4, y_test4 = train_test_split(x4, y4, test_size=0.2, random_state=1)\n",
    "\n",
    "# modeling\n",
    "RFC4 = RandomForestClassifier(n_estimators=10,class_weight ='balanced_subsample')\n",
    "RFC4.fit(x_train4,y_train4)\n",
    "y_hat4 = RFC4.predict(x_test4)\n",
    "\n",
    "# evaluating\n",
    "print('Model Evaluation:',jaccard_similarity_score(y_test4, y_hat4).round(4))\n",
    "y_prob4 = RFC4.predict_proba(x_test4)\n",
    "print('Probabilistic Evaluation:',log_loss(y_test4, y_prob4).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2]), array([29849,  9086], dtype=int64))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_hat4,return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's repeat the previous process but this time using the dataframe with external causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation: 0.5391\n",
      "Probabilistic Evaluation: 0.7443\n"
     ]
    }
   ],
   "source": [
    "x5 = collisions_external.drop('SEVERITYCODE',axis=1)\n",
    "y5 = collisions_external.SEVERITYCODE\n",
    "x_train5, x_test5, y_train5, y_test5 = train_test_split(x5, y5, test_size=0.2, random_state=1)\n",
    "\n",
    "# modeling\n",
    "LR5 = LogisticRegression(solver='lbfgs')\n",
    "LR5.fit(x_train5, y_train5)\n",
    "y_hat5 = LR5.predict(x_test5)\n",
    "\n",
    "# evaluating\n",
    "print('Model Evaluation:',jaccard_similarity_score(y_test5, y_hat5).round(4))\n",
    "y_prob5 = LR.predict_proba(x_test5)\n",
    "print('Probabilistic Evaluation:', log_loss(y_test5, y_prob5).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2]), array([12133, 11143], dtype=int64))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_hat5,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation: 0.6343\n",
      "Probabilistic Evaluation: 0.69\n"
     ]
    }
   ],
   "source": [
    "x6 = collisions[['INATTENTIONIND', 'UNDERINFL', 'SPEEDING']]\n",
    "y6 = collisions.SEVERITYCODE\n",
    "x_train6, x_test6, y_train6, y_test6 = train_test_split(x6, y6, test_size=0.2, random_state=1)\n",
    "\n",
    "#m modeling\n",
    "LR6 = LogisticRegression(solver='lbfgs', class_weight='balanced')\n",
    "LR6.fit(x_train6, y_train6)\n",
    "y_hat6 = LR6.predict(x_test6)\n",
    "\n",
    "# evaluating\n",
    "print('Model Evaluation:',jaccard_similarity_score(y_test6, y_hat6).round(4))\n",
    "y_prob6 = LR6.predict_proba(x_test6)\n",
    "print('Probabilistic Evaluation:',log_loss(y_test6, y_prob6).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2]), array([29849,  9086], dtype=int64))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_hat6,return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the case of RFC with external causes ('LIGHTCOND', 'ROADCOND', 'WEATHER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation: 0.5412\n",
      "Probabilistic Evaluation: 0.6874\n"
     ]
    }
   ],
   "source": [
    "# class_weight = 'none'\n",
    "x7 = collisions_external.drop('SEVERITYCODE',axis=1)\n",
    "y7 = collisions_external.SEVERITYCODE\n",
    "x_train7, x_test7, y_train7, y_test7 = train_test_split(x7, y7, test_size=0.2, random_state=1)\n",
    "\n",
    "# modeling\n",
    "RFC7 = RandomForestClassifier(n_estimators=10)\n",
    "RFC7.fit(x_train7,y_train7)\n",
    "y_hat7 = RFC7.predict(x_test7)\n",
    "\n",
    "# evaluating\n",
    "print('Model Evaluation:',jaccard_similarity_score(y_test7, y_hat7).round(4))\n",
    "y_prob7 = RFC7.predict_proba(x_test7)\n",
    "print('Probabilistic Evaluation:',log_loss(y_test7, y_prob7).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2]), array([ 8990, 14286], dtype=int64))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_hat7,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation: 0.4959\n",
      "Probabilistic Evaluation: 0.6877\n"
     ]
    }
   ],
   "source": [
    "# class_weight = 'balanced'\n",
    "x8 = collisions[['LIGHTCOND', 'ROADCOND', 'WEATHER']]\n",
    "y8 = collisions.SEVERITYCODE\n",
    "x_train8, x_test8, y_train8, y_test8 = train_test_split(x8, y8, test_size=0.2, random_state=1)\n",
    "\n",
    "# modeling\n",
    "RFC8 = RandomForestClassifier(n_estimators=10,class_weight = 'balanced')\n",
    "RFC8.fit(x_train8,y_train8)\n",
    "y_hat8 = RFC8.predict(x_test8)\n",
    "\n",
    "# evaluating\n",
    "print('Model Evaluation:',jaccard_similarity_score(y_test8, y_hat8).round(4))\n",
    "y_prob8 = RFC8.predict_proba(x_test8)\n",
    "print('Probabilistic Evaluation:',log_loss(y_test8, y_prob8).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2]), array([15529, 23406], dtype=int64))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_hat8,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation: 0.4959\n",
      "Probabilistic Evaluation: 0.6876\n"
     ]
    }
   ],
   "source": [
    "# class_weight = 'balanced_subsample'\n",
    "x9 = collisions[['LIGHTCOND', 'ROADCOND', 'WEATHER']]\n",
    "y9 = collisions.SEVERITYCODE\n",
    "x_train9, x_test9, y_train9, y_test9 = train_test_split(x9, y9, test_size=0.2, random_state=1)\n",
    "\n",
    "# modeling\n",
    "RFC9 = RandomForestClassifier(n_estimators=10,class_weight = 'balanced_subsample')\n",
    "RFC9.fit(x_train9,y_train9)\n",
    "y_hat9 = RFC9.predict(x_test9)\n",
    "\n",
    "# evaluating\n",
    "print('Model Evaluation:',jaccard_similarity_score(y_test9, y_hat9).round(4))\n",
    "y_prob9 = RFC9.predict_proba(x_test9)\n",
    "print('Probabilistic Evaluation:',log_loss(y_test9, y_prob9).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2]), array([15529, 23406], dtype=int64))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_hat9,return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally we observe the two casuses: internal and external, but this time we only use RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation: 0.5507\n",
      "Probabilistic Evaluation: 0.6864\n"
     ]
    }
   ],
   "source": [
    "# class_wieght = 'none'\n",
    "x10 = df_downsampled.drop('SEVERITYCODE',axis=1)\n",
    "y10 = df_downsampled.SEVERITYCODE\n",
    "x_train10, x_test10, y_train10, y_test10 = train_test_split(x10, y10, test_size=0.2, random_state=1)\n",
    "\n",
    "# modeling\n",
    "RFC10 = RandomForestClassifier(n_estimators=10)\n",
    "RFC10.fit(x_train10,y_train10)\n",
    "y_hat10 = RFC10.predict(x_test10)\n",
    "\n",
    "# evaluating\n",
    "print('Model Evaluation:',jaccard_similarity_score(y_test10, y_hat10).round(4))\n",
    "y_prob10 = RFC10.predict_proba(x_test10)\n",
    "print('Probabilistic Evaluation:',log_loss(y_test10, y_prob10).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2]), array([ 7039, 16237], dtype=int64))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_hat10,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation: 0.4735\n",
      "Probabilistic Evaluation: 0.6835\n"
     ]
    }
   ],
   "source": [
    "# class_weight = 'balanced'\n",
    "x11 = collisions[['INATTENTIONIND', 'UNDERINFL', 'SPEEDING','LIGHTCOND', 'ROADCOND', 'WEATHER']]\n",
    "y11 = collisions.SEVERITYCODE\n",
    "x_train11, x_test11, y_train11, y_test11 = train_test_split(x11, y11, test_size=0.2, random_state=1)\n",
    "\n",
    "# modeling\n",
    "RFC11 = RandomForestClassifier(n_estimators=10,class_weight = 'balanced')\n",
    "RFC11.fit(x_train11,y_train11)\n",
    "y_hat11 = RFC11.predict(x_test11)\n",
    "\n",
    "# evaluating\n",
    "print('Model Evaluation:',jaccard_similarity_score(y_test11, y_hat11).round(4))\n",
    "y_prob11 = RFC11.predict_proba(x_test11)\n",
    "print('Probabilistic Evaluation:',log_loss(y_test11, y_prob11).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2]), array([12480, 26455], dtype=int64))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_hat11,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation: 0.4779\n",
      "Probabilistic Evaluation: 0.6833\n"
     ]
    }
   ],
   "source": [
    "# class_weight = 'balanced_subsample'\n",
    "x12 = collisions[['INATTENTIONIND', 'UNDERINFL', 'SPEEDING','LIGHTCOND', 'ROADCOND', 'WEATHER']]\n",
    "y12 = collisions.SEVERITYCODE\n",
    "x_train12, x_test12, y_train12, y_test12 = train_test_split(x12, y12, test_size=0.2, random_state=1)\n",
    "\n",
    "# modeling\n",
    "RFC12 = RandomForestClassifier(n_estimators=10, class_weight='balanced_subsample')\n",
    "RFC12.fit(x_train12,y_train12)\n",
    "y_hat12 = RFC12.predict(x_test12)\n",
    "\n",
    "# evaluating\n",
    "print('Model Evaluation:',jaccard_similarity_score(y_test12, y_hat12).round(4))\n",
    "y_prob12 = RFC12.predict_proba(x_test12)\n",
    "print('Probabilistic Evaluation:',log_loss(y_test12, y_prob12).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2]), array([12893, 26042], dtype=int64))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_hat12,return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Results and Discussion__ <a name=\"results\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general the two models used (Logistic Regression, Random Forest Classifier) receive modest evaluations, both of which have no more than __63%__ accuracy in their evaluations with the Jaccard index. If we evaluate the probability that the model correctly classifies as prop damage or injurie, an improvement is observed that reaches up to 68% and 69%.\n",
    "\n",
    "The RFC model additionally provides important data that is the feature importance which is very useful for making recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the model for the internal causes that are attributed to the speed of the car, inattention while driving and the influence of alcohol are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Class_weight       | LR      |        | RFC     |        |\n",
    "|--------------------|---------|--------|---------|--------|\n",
    "|                    | Jaccard |LogLoss | Jaccard |LogLoss |\n",
    "| default            | 0.5349  |0.6900  | 0.5349  |0.6900  |        \n",
    "| balanced           | 0.6343  |0.6900  | 0.6343  |0.6895  |\n",
    "| subsample          | NA      |NA      | 0.6343  |0.6900  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The external causes referring to the light conditions, the state of the road, the weather; present the following evaluations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Class_weight       | LR      |        | RFC     |        |\n",
    "|--------------------|---------|--------|---------|--------|\n",
    "|                    | Jaccard |LogLoss | Jaccard |LogLoss |\n",
    "| default            | 0.5391  |0.7443  | 0.5412  |0.6874  |        \n",
    "| balanced           | 0.6343  |0.6900  | 0.4959  |0.6879  |\n",
    "| subsample          | NA      |NA      | 0.4959  |0.6876  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when modeling the complete dataset the precision drops to __47%__ but the probability of classification remains at __68%__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Class_weight       | RFC     |        |\n",
    "|--------------------|---------|--------|\n",
    "|                    | Jaccard |LogLoss |\n",
    "| default            | 0.5513  |0.6864  |\n",
    "| balanced           | 0.4741  |0.6842  |\n",
    "| subsample          | 0.47.35 |0.6843  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at internal causes, the RFC provides additional information such as feature importance, so using subsampling, the evaluations are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('INATTENTIONIND', 0.44), ('UNDERINFL', 0.34), ('SPEEDING', 0.22)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(x4.columns,RFC4.feature_importances_.round(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of external causes the RFC with subsample indicates that light conditions of the road is the 62% of the injuries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LIGHTCOND', 0.59), ('ROADCOND', 0.21), ('WEATHER', 0.2)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(x9.columns,RFC9.feature_importances_.round(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__When the six features are observed at the same time, a greater importance is clearly attributed to the light conditions (40%), then there is the influence of alcohol (16%) and road conditions(17%). It is striking that weather (6%) and speed (10%) are the features that least influence accidents with injuries to occupants.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('INATTENTIONIND', 0.11),\n",
       " ('UNDERINFL', 0.16),\n",
       " ('SPEEDING', 0.1),\n",
       " ('LIGHTCOND', 0.4),\n",
       " ('ROADCOND', 0.17),\n",
       " ('WEATHER', 0.06)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(x12.columns,RFC12.feature_importances_.round(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Conclusion__ <a name=\"conclusion\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When you go out to drive avoid drinking this can reduce injuries in traffic accidents by up to 34%. Respect the speed limits as you can reduce accidents by up to 22%, and above all do not get distracted while driving because 44% of accidents are caused by being distracted.\n",
    "### It is possible that on the road the weather is not good and that the track conditions are not favorable, this is out of your control but the most important thing is the light conditions, if you have a lot of difficulty in vision it is better to postpone the trip, or otherwise always use the high beams to have better visibility."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
